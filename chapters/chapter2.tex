\begin{savequote}[75mm]
But it is not conceivable that such a machine should produce different arrangements of words so as to give an appropriately meaningful answer to whatever is said in its presence, as the dullest of men can do.
\qauthor{Ren\'e Descartes}
\end{savequote}

\chapter{The Luna Game}

\section{Overview}

At the center of my proposed rating system is a two-player game that I call the Luna Game. Each player enters the game with a Smarts Rating, which has been assigned based on her performance in previous games. As the name suggests, the Smarts Rating is a proxy for the player's intelligence. The Smarts Rating of each player is hidden from the other player until the end of the game. The objective of the Luna Game is simple: guess the Smarts Rating of the other player. In other words, a player should strive to accurately evaluate the intelligence of her opponent. The winner of the Luna Game is the player whose guess is closest to the actual Smarts Rating of the other player. After the game, the opponent's guess is factored into the player's Smarts Rating so that the rating captures all the guesses of previous opponents.

As a player with a high Smarts Rating, why not ``play dumb''? This strategy would indeed induce an inaccurately low guess from the opponent, possibly leading to a win. However, the motives of a player reach beyond the scope of a single game. In addition to winning games, a player wants to achieve a high Smarts Rating. Since the rating depends on the guesses of all the player's opponents, she will need to ``play smart'' to accomplish her long term goal. The ``playing dumb'' method is not only detrimental to a player's rating, but also unsustainable as a consistent strategy; a player of that method will have her Smarts Rating lowered as a result, narrowing the margin between future opponents' guesses and her actual Smarts Rating if she continues to use the strategy. Players who remain and thrive will be those who play smart.

In designing the Luna Game, I sought to impose as few constraints as possible. The Game is meant to be a microcosm of the organic process for defining intelligence. Humans evaluate each other's intelligences through a series of questions and answers, often in the form of a written exam, but also informally through everyday conversations. The most natural notion of an individual's intelligence arises from the consensus of the people who perform these evaluations. A player's Smarts Rating is meant to reflect this natural notion; it is an aggregate of evaluations carried out by other players. To define the scope of an evaluation, I impose only those constraints necessary to motivate honest and repeated play.

A session of the Luna Game consists of three phases: the Interview Phase, the Response Phase, and the Guess Phase. During the Interview Phase, each player creates a set of five questions to pose to the opponent. In the Response Phase, each player responds to the other's questions. Finally, in the Guess Phase, each player receives responses back from her opponent, and must use the responses to guess her opponent's Smarts Rating. I describe each of these phases in detail throughout the rest of this chapter and illustrate the game through examples of play.

\section{Interview Phase}

A Luna Game begins with the Interview Phase. During this phase, each player prepares a set of five free-form questions to be given to the other player. The number of questions represents a tradeoff between the time required to complete the phase and the difficulty of the guessing task. With more questions, each player would need more time to construct the questions, increasing the likelihood that they will quit the game and leave the system. With fewer questions, construction time could be shortened, but the informativeness of the subsequent responses would suffer, and the Smarts Ratings would ultimately be less meaningful. I chose the number five to optimize this tradeoff, but the number may be adjusted in future iterations of the system. In a similar practical vein, I insist that questions be constructed in batch, rather than allowing for sequential question-response. Since the game is played online, allowing for back and forth would increase the length of each game and significantly decrease the probability that a game gets finished.

The other major consideration in the design of the Interview Phase is the form of the questions. The only constraint I impose is a limit of $5000$ characters per question. I do not insist that questions be actual questions, nor that they be in any particular language, nor that they expect a particular form of response. In natural language terms, the questions are of open domain, since I do not restrict the content of questions. I recognize that in practice, players may opt for yes-or-no or multiple choice questions, which could simplify the task of learning to guess ratings. Players may also limit the domain of their questions, since general form questions may be too difficult for current AI, so general questions may not meaningfully differentiate between them. Nonetheless, I leave the choice of question topic and form to the players themselves. I anticipate that players will find the optimal question types better than I as the game designer could, and that the question types will naturally evolve in correspondence with the evolution of the AI players.

\subsection{Instructions}

The following instructions are presented during the Interview Phase.
\begin{center}
\textit{You are now in the Interview Phase. Please enter a list of five questions for the other player. Keep in mind the following strategic hints:}

\begin{itemize}
\item \textit{Your questions should be as informative as possible for guessing the other player's Smarts Rating.}
\item \textit{Your questions should have a very wide range of difficulties.}
\item \textit{Your questions need not have ``right'' or ``wrong'' answers.}
\item \textit{Search engine access is allowed, so trivia questions will not be very informative.}
\item \textit{Do not assume that the other player is human!}
\end{itemize}
\end{center}

\subsection{Interview Strategy}

In preparing questions, a player knows nothing about her opponent. She must prepare for extremes --- a completely naive machine opponent or a very clever human opponent  --- and she also must be able to differentiate between players with Smarts Ratings in the middle of the spectrum. Given the competitive nature of the game, a player may be tempted to create a set of extremely hard questions. This choice would prove unwise, since the player will be unable to accurately guess the Smarts Rating of an opponent who gets all of the questions ``wrong''. A question set that is too easy will lead to the opposite problem. Thus an ideal set of questions will have a wide range of difficulty.

\subsection{Examples}

Below is an example of a question set. I choose questions from the web-based implementation of LRS described in Chapter $6$ to illustrate the range of possible question types and to demonstrate appropriate levels of difficulty. Early questions are aimed at differentiating between naive machines, while later questions are directed towards advanced human players. Each question is designed to induce a response that will reveal the intelligence of the opponent.

\begin{enumerate}
\item Do you like games?
\item People who live in Boston are called Bostonians. What is a person who lives in Cambridge, MA called?
\item l -|- l = ?
\item How do you define success?
\item If a hacker can determine when keys on your keyboard are pressed (without knowing which keys), how are you in danger?
\end{enumerate}

\section{Response Phase}

The Response Phase is a player's opportunity to convince her opponent that she is intelligent. Questions are received as soon as both players have finished the Interview Phase. Each player must then respond in free form to all five questions. Responses are not returned until both players have finished answering all questions. Like questions in the Interview Phase, responses are unconstrained in form, and only limited in length to $5000$ characters each. A player is motivated by the prospect of an increase in Smarts Rating to respond to the questions thoroughly and to the best of her ability.

\subsection{Instructions}

The following instructions are presented during the Response Phase.
\begin{center}
\textit{The other player has sent you questions! You are now in the Response Phase of the Luna Game. Please answer the following questions: [Question Set]. In answering the questions, keep in mind the following strategic hints:}
\begin{itemize}
\item \textit{You should answer the questions to the best of your ability.}
\item \textit{The other player will use your answers to guess your Smarts Rating.}
\item \textit{The higher the other player guesses, the higher your Smarts Rating will become.}
\end{itemize}
\end{center}

\subsection{Examples}

The responses below are also taken from the web-based implementation of LRS described in Chapter $6$.

\begin{enumerate}
\item Q: Do you like games? \\
A: Yes I love games
\item Q: People who live in Boston are called Bostonians. What is a person who lives in Cambridge, MA called?\\
A: An academic
\item Q: l -|- l = ?\\
A: Why are you using capital I's, and what in the world is ``-|-''?
\item Q: How do you define success?\\
A: Dictionary.com defines it as ``the favorable or prosperous termination of attempts or endeavors; the accomplishment of one's goals.''
\item Q: If a hacker can determine when keys on your keyboard are pressed (without knowing which keys), how are you in danger?\\
A: Ugh, this is a difficult one. It would make guessing password easier maybe, because the hacker would know the length of a password. It also depends on what other info is available to the hacker, such as Web addresses or sites visited. Hacker could also known and record when (times each day) the computer is not in use, making it easier to remotely control the computer without the user knowing.
\end{enumerate}

\section{Guess Phase}

After both players have responded to each other's questions, their responses are returned for evaluation. Each player then must formulate a guess of the other's Smarts Rating based on these responses. In practice, the player might also attempt to take into account the questions provided by the opponent, but since questions may be generated automatically, it is advisable to focus on the opponent's responses. The winner of the Luna Game is the player whose guess is closest to the actual Smarts Rating of her opponent.

A competitive player may consider guessing the lowest possible rating, knowing that the game will be lost, but the opponent's Smarts Rating will decrease as a result of the guess. However, this strategy offers no real benefit to the player, since Smarts Ratings are not rankings; the player's Smarts Rating will not improve as a result of the opponent's Smarts Rating suffering. (Nonetheless, I analyze the system-level effects of this strategy in Chapter $3$.) Thus the only rational strategy for guessing is to attempt to guess as close as possible to the actual Smarts Rating of the opponent.

\subsection{Instructions}

The following instructions are presented during the Guess Phase.
\begin{center}
\textit{The other player has responded to your questions! You are now in the Guess Phase of the Luna Game, which is the final phase. Below are the other's answers: [Answer Set] Based on these answers, please enter a guess of the other player's Smarts Rating.}
\end{center}
In addition, I provide functionality that encourages the player to evaluate each question individually on a sliding scale from 0 to 100. I prompt the player to assign the single question score by asking, ``How smart was this response?'' This process is optional, as I do not want to slow down the impatient player. However, a player is incentivized to use the sliding scales if they do not have a more sophisticated method of guessing ratings, since the single question scores can be automatically converted into a guess. These single question scores provide insight into the hardness of the natural language questions, effectively creating a dataset of questions annotated with difficulty.

\section{Game Conclusion}

After both players have provided guesses, the Luna Game is complete. The winner of the game is the player whose guess is closest (in terms of $L_1$ distance) to the actual Smarts Rating of their opponent. It is possible, though unlikely, for the game to end in a tie if the distance between guess and actual is equal for both players. In addition to reporting the outcome of the game, the system reveals the actual Smarts Rating of the opponent and the opponent's guess. The system also updates the players' Smarts Ratings so that it is the mean of all previous human opponent Guesses and reports these updates to the respective players. The mean was chosen for simplicity, though more sophisticated statistics that are adaptive, such as Elo Ratings, could also be used in the future. Machine guesses are not factored into Smarts Ratings.

\subsection{Example}
Below is an example of feedback at the end of a Luna Game.
\begin{center}
\textit{Your Luna Game is complete! Below are the results.}\\
\textit{Game Outcome: You won!}\\
\textit{Your New Smarts Rating: $78$}\\
\textit{Actual Other Player Smart Rating: $84$ (You guessed $81$)}\\
\textit{Other Player's Guess of Your Rating: $91$ (Your rating was $75$)}
\end{center}

\subsection{Conclusion of a Player's First Luna Game}

New players do not have Smarts Ratings until the end of their first game, at which point they are assigned the guess of their first opponent. The game is counted as an automatic win for the opponent, but not as a loss for the new player. This process is to avoid the possibility of the Smarts Rating equilibrium collapsing into a constant (see Chapter $3$).